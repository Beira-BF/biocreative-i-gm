There are 2 test files given:

 a. round1.in - the original sentences before tokenization

 b. TOKENIZED_CORPUS - the tokenized version of the sentences

The original sentence id numbers in these files have been replaced
with unique internal sentence ids.

A file similar to TAGGED_GENE_CORPUS in "train" and "(dev)test" is to be returned to us.
The tokenization of the returned file MUST MATCH the TOKENIZATION in TOKENIZED_CORPUS.

Thanks and good luck.

